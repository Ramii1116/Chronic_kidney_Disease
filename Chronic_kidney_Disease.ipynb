{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4931be47-19b9-4d29-81f1-53b537876e98",
   "metadata": {},
   "source": [
    "# Chronic Kidney Disease Prediction - Data Science Project\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "- Chronic Kidney Disease (CKD) is a global health issue that affects millions. Early prediction and diagnosis can significantly improve patient outcomes-. This project aims to develop predictive models for CKD using machine learning techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82859f42-e45f-4869-9f43-5f95831c0cb0",
   "metadata": {},
   "source": [
    "# 2. Problem Statement\n",
    "\n",
    "The goal is to classify whether a patient has CKD or not based on clinical data. This involves:\n",
    "\n",
    "- Preprocessing the dataset.\n",
    "\n",
    "- Building and evaluating machine learning models.\n",
    "\n",
    "- Comparing model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1988082e-e915-46fc-91b2-2d24eef50693",
   "metadata": {},
   "source": [
    "# 3. Dataset Overview\n",
    "\n",
    "Dataset: kidney_disease.csv\n",
    "\n",
    "The dataset contains clinical measurements and patient conditions, including:\n",
    "\n",
    "Features: Blood pressure, albumin levels, glucose levels, etc.\n",
    "\n",
    "Target: classification - whether the patient has CKD (ckd) or not (notckd)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a7a5e0-9a79-41be-b6de-fa1e2f756b06",
   "metadata": {},
   "source": [
    "# 4. Steps in the Project\n",
    "\n",
    "## Import necessary libraries.\n",
    "\n",
    "- Load and explore the dataset.\n",
    "\n",
    "- Preprocess the data (cleaning, encoding, handling missing values).\n",
    "\n",
    "- Train and evaluate machine learning models.\n",
    "\n",
    "- Compare performance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4682a9ca-c095-4363-9920-f00f17b364ad",
   "metadata": {},
   "source": [
    "# 5. Code and Explanations\n",
    "\n",
    "## 5.1 Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a922a71-8323-47d3-945a-7324057aa31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3126b49-5fdf-4953-b1e5-4d9bf5dcbd44",
   "metadata": {},
   "source": [
    "- Importing libraries for data manipulation, preprocessing, machine learning models, and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2e3461-5d34-4045-ba15-01aaefb8dc23",
   "metadata": {},
   "source": [
    "### Loading and Exploring the Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7b76f41-9573-4231-95e2-b31ed4083631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id   age     bp     sg   al   su       rbc        pc         pcc  \\\n",
      "0   0  48.0   80.0  1.020  1.0  0.0       NaN    normal  notpresent   \n",
      "1   1   7.0   50.0  1.020  4.0  0.0       NaN    normal  notpresent   \n",
      "2   2  62.0   80.0  1.010  2.0  3.0    normal    normal  notpresent   \n",
      "3   3  48.0   70.0  1.005  4.0  0.0    normal  abnormal     present   \n",
      "4   4  51.0   80.0  1.010  2.0  0.0    normal    normal  notpresent   \n",
      "5   5  60.0   90.0  1.015  3.0  0.0       NaN       NaN  notpresent   \n",
      "6   6  68.0   70.0  1.010  0.0  0.0       NaN    normal  notpresent   \n",
      "7   7  24.0    NaN  1.015  2.0  4.0    normal  abnormal  notpresent   \n",
      "8   8  52.0  100.0  1.015  3.0  0.0    normal  abnormal     present   \n",
      "9   9  53.0   90.0  1.020  2.0  0.0  abnormal  abnormal     present   \n",
      "\n",
      "           ba  ...  pcv     wc   rc  htn   dm  cad appet   pe  ane  \\\n",
      "0  notpresent  ...   44   7800  5.2  yes  yes   no  good   no   no   \n",
      "1  notpresent  ...   38   6000  NaN   no   no   no  good   no   no   \n",
      "2  notpresent  ...   31   7500  NaN   no  yes   no  poor   no  yes   \n",
      "3  notpresent  ...   32   6700  3.9  yes   no   no  poor  yes  yes   \n",
      "4  notpresent  ...   35   7300  4.6   no   no   no  good   no   no   \n",
      "5  notpresent  ...   39   7800  4.4  yes  yes   no  good  yes   no   \n",
      "6  notpresent  ...   36    NaN  NaN   no   no   no  good   no   no   \n",
      "7  notpresent  ...   44   6900    5   no  yes   no  good  yes   no   \n",
      "8  notpresent  ...   33   9600  4.0  yes  yes   no  good   no  yes   \n",
      "9  notpresent  ...   29  12100  3.7  yes  yes   no  poor   no  yes   \n",
      "\n",
      "  classification  \n",
      "0            ckd  \n",
      "1            ckd  \n",
      "2            ckd  \n",
      "3            ckd  \n",
      "4            ckd  \n",
      "5            ckd  \n",
      "6            ckd  \n",
      "7            ckd  \n",
      "8            ckd  \n",
      "9            ckd  \n",
      "\n",
      "[10 rows x 26 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 26 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   id              400 non-null    int64  \n",
      " 1   age             391 non-null    float64\n",
      " 2   bp              388 non-null    float64\n",
      " 3   sg              353 non-null    float64\n",
      " 4   al              354 non-null    float64\n",
      " 5   su              351 non-null    float64\n",
      " 6   rbc             248 non-null    object \n",
      " 7   pc              335 non-null    object \n",
      " 8   pcc             396 non-null    object \n",
      " 9   ba              396 non-null    object \n",
      " 10  bgr             356 non-null    float64\n",
      " 11  bu              381 non-null    float64\n",
      " 12  sc              383 non-null    float64\n",
      " 13  sod             313 non-null    float64\n",
      " 14  pot             312 non-null    float64\n",
      " 15  hemo            348 non-null    float64\n",
      " 16  pcv             330 non-null    object \n",
      " 17  wc              295 non-null    object \n",
      " 18  rc              270 non-null    object \n",
      " 19  htn             398 non-null    object \n",
      " 20  dm              398 non-null    object \n",
      " 21  cad             398 non-null    object \n",
      " 22  appet           399 non-null    object \n",
      " 23  pe              399 non-null    object \n",
      " 24  ane             399 non-null    object \n",
      " 25  classification  400 non-null    object \n",
      "dtypes: float64(11), int64(1), object(14)\n",
      "memory usage: 81.4+ KB\n",
      "None\n",
      "Index(['id', 'age', 'bp', 'sg', 'al', 'su', 'rbc', 'pc', 'pcc', 'ba', 'bgr',\n",
      "       'bu', 'sc', 'sod', 'pot', 'hemo', 'pcv', 'wc', 'rc', 'htn', 'dm', 'cad',\n",
      "       'appet', 'pe', 'ane', 'classification'],\n",
      "      dtype='object')\n",
      "               id         age          bp          sg          al          su  \\\n",
      "count  400.000000  391.000000  388.000000  353.000000  354.000000  351.000000   \n",
      "mean   199.500000   51.483376   76.469072    1.017408    1.016949    0.450142   \n",
      "std    115.614301   17.169714   13.683637    0.005717    1.352679    1.099191   \n",
      "min      0.000000    2.000000   50.000000    1.005000    0.000000    0.000000   \n",
      "25%     99.750000   42.000000   70.000000    1.010000    0.000000    0.000000   \n",
      "50%    199.500000   55.000000   80.000000    1.020000    0.000000    0.000000   \n",
      "75%    299.250000   64.500000   80.000000    1.020000    2.000000    0.000000   \n",
      "max    399.000000   90.000000  180.000000    1.025000    5.000000    5.000000   \n",
      "\n",
      "              bgr          bu          sc         sod         pot        hemo  \n",
      "count  356.000000  381.000000  383.000000  313.000000  312.000000  348.000000  \n",
      "mean   148.036517   57.425722    3.072454  137.528754    4.627244   12.526437  \n",
      "std     79.281714   50.503006    5.741126   10.408752    3.193904    2.912587  \n",
      "min     22.000000    1.500000    0.400000    4.500000    2.500000    3.100000  \n",
      "25%     99.000000   27.000000    0.900000  135.000000    3.800000   10.300000  \n",
      "50%    121.000000   42.000000    1.300000  138.000000    4.400000   12.650000  \n",
      "75%    163.000000   66.000000    2.800000  142.000000    4.900000   15.000000  \n",
      "max    490.000000  391.000000   76.000000  163.000000   47.000000   17.800000  \n",
      "(400, 26)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"kidney_disease.csv\", header=0, na_values=\"?\")\n",
    "print(df.head(10))\n",
    "print(df.info())\n",
    "print(df.columns)\n",
    "print(df.describe())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec67b061-313d-49fb-a7d6-9a9ae92fe102",
   "metadata": {},
   "source": [
    "\n",
    "Load the dataset and inspect its structure, size, and basic statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86c8c1b-6676-4cbb-9b7f-68da72567d4f",
   "metadata": {},
   "source": [
    "## Renaming Columns: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77d29e3a-aa78-4556-ba79-3669db5e217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_names = {\n",
    "    \"bp\": \"blood_pressure\",\n",
    "    \"sg\": \"specific_gravity\",\n",
    "    \"al\": \"albumin\",\n",
    "    \"su\": \"sugar\",\n",
    "    \"rbc\": \"red_blood_cells\",\n",
    "    \"pc\": \"pus_cell\",\n",
    "    \"pcc\": \"pus_cell_clumps\",\n",
    "    \"ba\": \"bacteria\",\n",
    "    \"bgr\": \"blood_glucose_random\",\n",
    "    \"bu\": \"blood_urea\",\n",
    "    \"sc\": \"serum_creatinine\",\n",
    "    \"sod\": \"sodium\",\n",
    "    \"pot\": \"potassium\",\n",
    "    \"hemo\": \"haemoglobin\",\n",
    "    \"pcv\": \"packed_cell_volume\",\n",
    "    \"wc\": \"white_blood_cell_count\",\n",
    "    \"rc\": \"red_blood_cell_count\",\n",
    "    \"htn\": \"hypertension\",\n",
    "    \"dm\": \"diabetes_mellitus\",\n",
    "    \"cad\": \"coronary_artery_disease\",\n",
    "    \"appet\": \"appetite\",\n",
    "    \"pe\": \"pedal_edema\",\n",
    "    \"ane\": \"anemia\",\n",
    "    \"classification\": \"classification\"\n",
    "}\n",
    "df.rename(columns=cols_names, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fdef44-b29f-496d-b773-1d298dd5058c",
   "metadata": {},
   "source": [
    "\n",
    "- Renaming columns for clarity and better interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c7ef67-be81-4a19-8b1e-1cc18f8e5a05",
   "metadata": {},
   "source": [
    "## Data Type Conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e72d518b-11d1-42b4-84ea-27afee8aff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['red_blood_cell_count'] = pd.to_numeric(df['red_blood_cell_count'], errors='coerce')\n",
    "df['packed_cell_volume'] = pd.to_numeric(df['packed_cell_volume'], errors='coerce')\n",
    "df['white_blood_cell_count'] = pd.to_numeric(df['white_blood_cell_count'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8863b4-4986-49a5-8e4e-13762d2d30b7",
   "metadata": {},
   "source": [
    "\n",
    "- Converts selected columns to numeric, replacing invalid values with NaN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f106dd90-09ef-4ea5-9131-7e17e73d22c0",
   "metadata": {},
   "source": [
    "## Dropping Irrelevant Columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f524676-5175-47c0-9d09-2e80598f52f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"id\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8164598-2da9-40aa-8b24-fc09e12c58cf",
   "metadata": {},
   "source": [
    "Drops the id column as it doesn’t contribute to analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228280db-f107-4200-8199-1494af29a627",
   "metadata": {},
   "source": [
    "## Handling Inconsistent Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b04e52d3-42fd-42b7-9dbe-21eaed56e96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['diabetes_mellitus'] = df['diabetes_mellitus'].replace({'\\tno': 'no', '\\tyes': 'yes', ' yes': 'yes'})\n",
    "df['coronary_artery_disease'] = df['coronary_artery_disease'].replace('\\tno', 'no')\n",
    "df['classification'] = df['classification'].replace('ckd\\t', 'ckd')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2249d086-e8f2-4625-b11b-ae5bd3b97a41",
   "metadata": {},
   "source": [
    "\n",
    "Fixes inconsistent entries such as tabs or extra spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d428ad-1f71-4a9d-8cea-eca66c000306",
   "metadata": {},
   "source": [
    "## Encoding Categorical Variables and Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16102002-414d-431e-b89b-f985c33e66f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_value = {\n",
    "    \"red_blood_cells\": {\"normal\": 1, \"abnormal\": 0},\n",
    "    \"pus_cell\": {\"normal\": 1, \"abnormal\": 0},\n",
    "    \"pus_cell_clumps\": {\"present\": 1, \"notpresent\": 0},\n",
    "    \"bacteria\": {\"present\": 1, \"notpresent\": 0},\n",
    "    \"hypertension\": {\"yes\": 1, \"no\": 0},\n",
    "    \"diabetes_mellitus\": {\"yes\": 1, \"no\": 0},\n",
    "    \"coronary_artery_disease\": {\"yes\": 1, \"no\": 0},\n",
    "    \"appetite\": {\"good\": 1, \"poor\": 0},\n",
    "    \"pedal_edema\": {\"yes\": 1, \"no\": 0},\n",
    "    \"anemia\": {\"yes\": 1, \"no\": 0},\n",
    "    \"classification\": {\"ckd\": 1, \"notckd\": 0}\n",
    "}\n",
    "df.replace(conv_value, inplace=True)\n",
    "df.fillna(round(df.mean(), 2), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6419105f-99ec-422d-917b-aab3ffad895c",
   "metadata": {},
   "source": [
    "- Encodes categorical variables and fills missing values with column means."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a95e2b8-2157-4d6d-bd08-b6bfd812b009",
   "metadata": {},
   "source": [
    "## Splitting Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e40e2b34-99f6-467e-8eef-506b008a463b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abce756-cdd5-4621-89c4-27960fc87634",
   "metadata": {},
   "source": [
    "- Separates the dataset into features (x) and target variable (y)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc754744-28db-4b09-8246-5ccd5e7f326b",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b461cd91-d4ad-49e4-b88c-323fce316b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Decision Trees\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"K Neighbors\": KNeighborsClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3ae8a2-4284-4ba5-8f82-bd62e980cf93",
   "metadata": {},
   "source": [
    "- Defines a dictionary of machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb503b3-8194-4bb9-a4dc-566b2b1ed7cb",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a832f345-e8c1-41c3-8b68-6261904dae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = {}\n",
    "test_acc = {}\n",
    "cv_score_train = {}\n",
    "precision_train = {}\n",
    "recall_train = {}\n",
    "f1_train = {}\n",
    "best_random_state = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    train_acc_temp = []\n",
    "    test_acc_temp = []\n",
    "    cv_temp = []\n",
    "\n",
    "    for i in range(0, 100):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, random_state=i)\n",
    "        scaler = MinMaxScaler()\n",
    "        x_train_scaled = scaler.fit_transform(x_train)\n",
    "        x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "        model.fit(x_train_scaled, y_train)\n",
    "        ypred_train = model.predict(x_train_scaled)\n",
    "        ypred_test = model.predict(x_test_scaled)\n",
    "\n",
    "        cv_temp.append(cross_val_score(model, x_train_scaled, y_train, cv=5).mean())\n",
    "        train_acc_temp.append(accuracy_score(y_train, ypred_train))\n",
    "        test_acc_temp.append(accuracy_score(y_test, ypred_test))\n",
    "\n",
    "    em = pd.DataFrame({\"train_acc\": train_acc_temp, \"cv\": cv_temp, \"test_acc\": test_acc_temp})\n",
    "    gm = em[(abs(em[\"test_acc\"] - em[\"cv\"]) <= 0.05)]\n",
    "    rs = gm[gm[\"test_acc\"] == gm[\"test_acc\"].max()].index.tolist()[0]\n",
    "    best_random_state[name] = rs\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, random_state=rs)\n",
    "    x_train_scaled = scaler.fit_transform(x_train)\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "    model.fit(x_train_scaled, y_train)\n",
    "    ypred_train = model.predict(x_train_scaled)\n",
    "    ypred_test = model.predict(x_test_scaled)\n",
    "\n",
    "    train_acc[name] = accuracy_score(y_train, ypred_train)\n",
    "    test_acc[name] = accuracy_score(y_test, ypred_test)\n",
    "    cv_score_train[name] = cross_val_score(model, x_train_scaled, y_train, cv=5).mean()\n",
    "    precision_train[name] = precision_score(y_train, ypred_train, average='weighted')\n",
    "    recall_train[name] = recall_score(y_train, ypred_train, average='weighted')\n",
    "    f1_train[name] = f1_score(y_train, ypred_train, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e222216-ba33-4dbe-8833-aa498c16c1b0",
   "metadata": {},
   "source": [
    "- Trains and evaluates each model using cross-validation and selects the best random state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742a6de1-0f5d-4737-86ec-4a69ae2c1899",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f700ce74-6d31-460e-bb52-657dfe80aa1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Best Random State: 4\n",
      "Train Accuracy: 0.990625\n",
      "Test Accuracy: 1.0\n",
      "CV Score (Train): 0.98125\n",
      "Precision (Train): 0.99085\n",
      "Recall (Train): 0.990625\n",
      "F1 Score (Train): 0.9906461507556324\n",
      "__________________________________________________\n",
      "Model: SVM\n",
      "Best Random State: 0\n",
      "Train Accuracy: 0.996875\n",
      "Test Accuracy: 1.0\n",
      "CV Score (Train): 0.9875\n",
      "Precision (Train): 0.996900406504065\n",
      "Recall (Train): 0.996875\n",
      "F1 Score (Train): 0.9968774218548179\n",
      "__________________________________________________\n",
      "Model: Decision Trees\n",
      "Best Random State: 1\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 1.0\n",
      "CV Score (Train): 0.9625\n",
      "Precision (Train): 1.0\n",
      "Recall (Train): 1.0\n",
      "F1 Score (Train): 1.0\n",
      "__________________________________________________\n",
      "Model: Random Forest\n",
      "Best Random State: 0\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 1.0\n",
      "CV Score (Train): 0.99375\n",
      "Precision (Train): 1.0\n",
      "Recall (Train): 1.0\n",
      "F1 Score (Train): 1.0\n",
      "__________________________________________________\n",
      "Model: K Neighbors\n",
      "Best Random State: 0\n",
      "Train Accuracy: 0.990625\n",
      "Test Accuracy: 1.0\n",
      "CV Score (Train): 0.975\n",
      "Precision (Train): 0.99085\n",
      "Recall (Train): 0.990625\n",
      "F1 Score (Train): 0.9906461507556324\n",
      "__________________________________________________\n",
      "Model: XGBoost\n",
      "Best Random State: 1\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 1.0\n",
      "CV Score (Train): 0.984375\n",
      "Precision (Train): 1.0\n",
      "Recall (Train): 1.0\n",
      "F1 Score (Train): 1.0\n",
      "__________________________________________________\n",
      "Model: AdaBoost\n",
      "Best Random State: 0\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 1.0\n",
      "CV Score (Train): 0.996875\n",
      "Precision (Train): 1.0\n",
      "Recall (Train): 1.0\n",
      "F1 Score (Train): 1.0\n",
      "__________________________________________________\n",
      "Model: Naive Bayes\n",
      "Best Random State: 31\n",
      "Train Accuracy: 0.95\n",
      "Test Accuracy: 0.9875\n",
      "CV Score (Train): 0.94375\n",
      "Precision (Train): 0.952713067602301\n",
      "Recall (Train): 0.95\n",
      "F1 Score (Train): 0.9503932770326212\n",
      "__________________________________________________\n",
      "Model: Gradient Boosting\n",
      "Best Random State: 1\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 1.0\n",
      "CV Score (Train): 0.978125\n",
      "Precision (Train): 1.0\n",
      "Recall (Train): 1.0\n",
      "F1 Score (Train): 1.0\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for name in models.keys():\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Best Random State: {best_random_state[name]}\")\n",
    "    print(f\"Train Accuracy: {train_acc[name]}\")\n",
    "    print(f\"Test Accuracy: {test_acc[name]}\")\n",
    "    print(f\"CV Score (Train): {cv_score_train[name]}\")\n",
    "    print(f\"Precision (Train): {precision_train[name]}\")\n",
    "    print(f\"Recall (Train): {recall_train[name]}\")\n",
    "    print(f\"F1 Score (Train): {f1_train[name]}\")\n",
    "    print(\"_\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11112e78-62c2-4f90-808c-7b5cabc0b740",
   "metadata": {},
   "source": [
    " Displays the performance metrics for all models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2554b6cb-0e18-4d69-8731-95fac0868e62",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion\n",
    "- This project successfully tackled the challenge of predicting Chronic Kidney Disease (CKD) using machine learning techniques. By systematically preprocessing the dataset, addressing inconsistencies, and encoding categorical variables, the project ensured data readiness for analysis. Several models, including Logistic Regression, Random Forest, SVM, and XGBoost, were trained and evaluated using metrics like accuracy, precision, recall, and F1-score.\n",
    "\n",
    "- The rigorous approach of leveraging cross-validation and identifying optimal random states for model stability ensured reliable and interpretable results. The best-performing models exhibited high accuracy and consistent performance across training and testing phases, highlighting their potential for real-world application.\n",
    "\n",
    "- Overall, this project underscores the significance of data science in healthcare, showcasing how predictive analytics can support early CKD diagnosis and improve patient outcomes. Future enhancements, such as hyperparameter tuning and deployment in clinical settings, can further elevate the utility of these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4811d5dc-eb61-40e8-b002-0a3689c88ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
